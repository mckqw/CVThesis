
@article{thomas_code_2002,
	title = {A code of ethics for public health},
	volume = {92},
	issn = {00900036},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1447186/pdf/0921057.pdf},
	doi = {10.2105/AJPH.92.7.1057},
	abstract = {The process of writing, disseminating, and adoption a code of ethics for public health workers is discussed, and the principles of the new code of ethics are outlined.},
	pages = {1057},
	number = {7},
	journaltitle = {Am J Public Health},
	author = {Thomas, James C. and Sage, Michael and Dillenberg, Jack and Guillory, V. James},
	date = {2002},
	pmid = {12084677}
}

@article{lowe_distinctive_2004,
	title = {Distinctive image features from scale-invariant keypoints},
	volume = {60},
	issn = {09205691},
	doi = {10.1023/B:VISI.0000029664.99615.94},
	abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
	pages = {91--110},
	number = {2},
	journaltitle = {International Journal of Computer Vision},
	author = {Lowe, David G.},
	date = {2004},
	pmid = {20064111},
	keywords = {Image matching, Invariant features, Object recognition, Scale invariance},
	file = {Lowe - 2004 - Distinctive image features from scale-invariant ke.pdf:C\:\\Users\\bass1\\Zotero\\storage\\CCNBGHDU\\Lowe - 2004 - Distinctive image features from scale-invariant ke.pdf:application/pdf}
}

@article{gao_real-time_2015,
	title = {Real-Time Multipedestrian Tracking in Traffic Scenes via an {RGB}-D-Based Layered Graph Model},
	volume = {16},
	issn = {15249050},
	doi = {10.1109/TITS.2015.2423709},
	abstract = {Multipedestrian tracking in traffic scenes is challenging due to cluttered backgrounds and serious occlusions. In this paper, we propose a layered graph model in image ({RGB}) and depth (D) domains for real-time robust multipedestrian tracking. The motivation is to investigate high-level constraints in {RGB}-D data association and to improve the optimization from the trajectory level to the layer level. To construct a layered graph, we define constraints in the depth domain so that pedestrian objects in the image domain are assigned to proper layers. We use pedestrian detection responses in the {RGB} domain as graph nodes, and we integrate 3-D motion, appearance, and depth features as graph edges. An online updating depth factor is defined to describe the depth relationships among the observations in and out of the layers, and the occlusion issue is processed with an analytical layer-level strategy. With a heuristic label switching algorithm, multiple pedestrian objects are optimally associated and tracked. Experiments and comparison on five public data sets show that our proposed approach significantly reduces pedestrian's {ID} switch and improves tracking accuracy in the cases of serious occlusions.},
	pages = {2814--2825},
	number = {5},
	journaltitle = {{IEEE} Transactions on Intelligent Transportation Systems},
	author = {Gao, Shan and Han, Zhenjun and Li, Ce and Ye, Qixiang and Jiao, Jianbin},
	date = {2015},
	keywords = {layered graph model, Multi-pedestrian tracking, occlusion, {RGB}-D data}
}

@article{choi_general_2013,
	title = {A general framework for tracking multiple people from a moving camera},
	volume = {35},
	issn = {01628828},
	doi = {10.1109/TPAMI.2012.248},
	abstract = {In this paper, we present a general framework for tracking multiple, possibly interacting, people from a mobile vision platform. To determine all of the trajectories robustly and in a 3D coordinate system, we estimate both the camera's ego-motion and the people's paths within a single coherent framework. The tracking problem is framed as finding the {MAP} solution of a posterior probability, and is solved using the reversible jump Markov chain Monte Carlo ({RJ}-{MCMC}) particle filtering method. We evaluate our system on challenging datasets taken from moving cameras, including an outdoor street scene video dataset, as well as an indoor {RGB}-D dataset collected in an office. Experimental evidence shows that the proposed method can robustly estimate a camera's motion from dynamic scenes and stably track people who are moving independently or interacting.},
	pages = {1577--1591},
	number = {7},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Choi, Wongun and Pantofaru, Caroline and Savarese, Silvio},
	date = {2013},
	pmid = {23681988},
	keywords = {Multitarget tracking, people tracking, person detection, {RJ}-{MCMC} particle filtering}
}

@book{szeliski_computer_2011,
	location = {London},
	edition = {11th},
	title = {Computer Vision: Algorithms and Applications},
	volume = {5},
	isbn = {978-1-84882-934-3},
	url = {http://research.microsoft.com/en-us/um/people/szeliski/book/drafts/szelski_20080330am_draft.pdf http://link.springer.com/10.1007/978-1-84882-935-0},
	series = {Texts in Computer Science},
	abstract = {As humans, we perceive the three-dimensional structure of the world around us with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem, and what is the current state of the art?Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging and fun consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos.More than just a source of "recipes", this text/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting this process to produce the best possible descriptions of a scene. Exercises are presented throughout the book, with a heavy emphasis on testing algorithms.Suitable for either an undergraduate or a graduate-level course in computer vision, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries.Dr. Richard Szeliski has over twenty years' experience in computer vision research, most notably at Digital Equipment Corporation and Microsoft.},
	pagetotal = {832},
	publisher = {Springer London},
	author = {Szeliski, Richard},
	date = {2011},
	doi = {10.1007/978-1-84882-935-0},
	pmid = {16259003},
	file = {Szeliski - 2011 - Computer Vision Algorithms and Applications.pdf:C\:\\Users\\bass1\\Zotero\\storage\\VDKQUA8J\\Szeliski - 2011 - Computer Vision Algorithms and Applications.pdf:application/pdf}
}

@inproceedings{dalal_histograms_2005,
	location = {Montbonnot-Saint-Martin, France},
	title = {Histograms of Oriented Gradients for Human Detection},
	volume = {1},
	isbn = {0-7695-2372-2},
	url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=1467360&contentType=Conference+Publications&searchField=Search_All&queryText=Histograms+of+oriented+gradients+for+human+detection http://ieeexplore.ieee.org/document/1467360/},
	doi = {10.1109/CVPR.2005.177},
	abstract = {We study the question of feature sets for robust visual object recognition; adopting linear {SVM} based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient ({HOG}) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original {MIT} pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
	pages = {886--893},
	booktitle = {2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
	publisher = {{IEEE}},
	author = {Dalal, N. and Triggs, B.},
	date = {2005},
	pmid = {9230594},
	file = {Dalal and Triggs - 2005 - Histograms of Oriented Gradients for Human Detecti.pdf:C\:\\Users\\bass1\\Zotero\\storage\\XIFCFCGY\\Dalal and Triggs - 2005 - Histograms of Oriented Gradients for Human Detecti.pdf:application/pdf}
}

@article{vondrick_visualizing_2016,
	title = {Visualizing Object Detection Features},
	volume = {119},
	issn = {15731405},
	doi = {10.1007/s11263-016-0884-7},
	abstract = {We introduce algorithms to visualize feature spaces used by object detectors. The tools in this paper allow a human to put on ‘{HOG} goggles' and perceive the visual world as a {HOG} based object detector sees it. We found that these visualizations allow us to analyze object detection systems in new ways and gain new insight into the detector's fail- ures. For example, when we visualize the features for high scoring false alarms, we discovered that, although they are clearly wrong in image space, they do look deceptively sim- ilar to true positives in feature space. This result suggests that many of these false alarms are caused by our choice of feature space, and indicates that creating a better learning algorithm or building bigger datasets is unlikely to correct these errors. By visualizing feature spaces, we can gain a more intuitive understanding of our detection systems.},
	pages = {145--158},
	number = {2},
	journaltitle = {International Journal of Computer Vision},
	author = {Vondrick, Carl and Khosla, Aditya and Pirsiavash, Hamed and Malisiewicz, Tomasz and Torralba, Antonio},
	date = {2016},
	keywords = {Feature visualization, Object detection, Visual recognition}
}

@article{bay_speeded-up_2008,
	title = {Speeded-Up Robust Features ({SURF})},
	volume = {110},
	issn = {10773142},
	doi = {10.1016/j.cviu.2007.09.014},
	abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined {SURF} (Speeded-Up Robust Features). {SURF} approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with {SURF}'s application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline {SURF}'s usefulness in a broad range of topics in computer vision. ?? 2007 Elsevier Inc. All rights reserved.},
	pages = {346--359},
	number = {3},
	journaltitle = {Computer Vision and Image Understanding},
	author = {Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and Van Gool, Luc},
	date = {2008},
	pmid = {16081019},
	keywords = {Object recognition, Camera calibration, Feature description, Interest points, Local features}
}

@book{contributors_computer_2018,
	title = {Computer chess - Wikipedia},
	url = {https://en.wikipedia.org/wiki/Computer_chess},
	author = {Contributors, Wikipedia},
	urldate = {2018-05-06},
	date = {2018}
}

@article{dollar_fast_2014,
	title = {Fast feature pyramids for object detection},
	volume = {36},
	issn = {01628828},
	doi = {10.1109/TPAMI.2014.2300479},
	abstract = {Multi-resolution image features may be approximated via extrapolation from nearby scales, rather than being computed explicitly. This fundamental insight allows us to design object detection algorithms that are as accurate, and considerably faster, than the state-of-the-art. The computational bottleneck of many modern detectors is the computation of features at every scale of a finely- sampled image pyramid. Our key insight is that one may compute finely sampled feature pyramids at a fraction of the cost, without sacrificing performance: for a broad family of features we find that features computed at octave-spaced scale intervals are sufficient to approximate features on a finely-sampled pyramid. Extrapolation is inexpensive as compared to direct feature computation. As a result, our approximation yields considerable speedups with negligible loss in detection accuracy. We modify three diverse visual recognition systems to use fast feature pyramids and show results on both pedestrian detection (measured on the Caltech, {INRIA}, {TUD}-Brussels and {ETH} datasets) and general object detection (measured on the {PASCAL} {VOC}). The approach is general and is widely applicable to vision algorithms requiring fine-grained multi-scale analysis. Our approximation is valid for images with broad spectra (most natural images) and fails for images with narrow band-pass spectra (e.g. periodic textures). Index},
	pages = {1532--1545},
	number = {8},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Dollar, Piotr and Appel, Ron and Belongie, Serge and Perona, Pietro},
	date = {2014},
	pmid = {26353336},
	keywords = {image pyramids, natural image statistics, object detection, pedestrian detection, real-time systems, Visual features}
}

@report{papert_summer_1966,
	location = {Boston, {MA}},
	title = {The Summer Vision Project},
	url = {http://hdl.handle.net/1721.1/6125},
	abstract = {The summer vision project is an attempt to use our summer workers effectively in the construction of a significant part of a visual system. The particular task was chosen partly because it can be segmented into sub-problems which allow individuals to work independently and yet participate in the construction of a system complex enough to be real landmark in the development of "pattern recognition". The basic structure is fixed for the first phase of work extending to some point in July. Everyone is invited to contribute to the discussion of the second phase. Sussman is coordinator of "Vision Project" meetings and should be consulted by anyone who wishes to participate. The primary goal of the project is to construct a system of programs which will divide a vidisector picture into regions such as likely objects, likely background areas and chaos. We shall call this part of its operation {FIGURE}-{GROUND} analysis. It will be impossible to do this without considerable analysis of shape and surface properties, so {FIGURE}-{GROUND} analysis is really inseparable in practice from the second goal which is {REGION} {DESCRIPTION}. The final goal is {OBJECT} {IDENTIFICATION} which will actually name objects by matching them with a vocabulary of known objects.},
	pages = {6},
	institution = {Massachusetts Institute of Technology},
	author = {Papert, Seymour A. and Minsky, Marvin},
	date = {1966}
}

@article{thrun_stanley:_2007,
	title = {Stanley: The robot that won the {DARPA} Grand Challenge},
	volume = {36},
	issn = {16107438},
	doi = {10.1007/978-3-540-73429-1_1},
	abstract = {This article describes the robot Stanley, which won the 2005 {DARPA} Grand Challenge. Stanley was developed for high-speed desert driving without manual intervention. The robot's software system relied predominately on state-of-the-art artificial intelligence technologies, such as machine learning and probabilistic reasoning. This paper describes the major components of this architecture, and discusses the results of the Grand Chal-lenge race.},
	pages = {1--43},
	journaltitle = {Springer Tracts in Advanced Robotics},
	author = {Thrun, Sebastian and Montemerlo, Mike and Dahlkamp, Hendrik and Stavens, David and Aron, Andrei and Diebel, James and Fong, Philip and Gale, John and Halpenny, Morgan and Hoffmann, Gabriel and Lau, Kenny and Oakley, Celia and Palatucci, Mark and Pratt, Vaughan and Stang, Pascal and Strohband, Sven and Dupont, Cedric and Jendrossek, Lars Erik and Koelen, Christian and Markey, Charles and Rummel, Carlo and van Niekerk, Joe and Jensen, Eric and Alessandrini, Philippe and Bradski, Gary and Davies, Bob and Ettinger, Scott and Kaehler, Adrian and Nefian, Ara and Mahoney, Pamela},
	date = {2007},
	pmid = {22164016}
}

@inproceedings{bansal_real-time_2010,
	title = {A real-time pedestrian detection system based on structure and appearance classification},
	isbn = {978-1-4244-5038-1},
	doi = {10.1109/ROBOT.2010.5509841},
	abstract = {We present a real-time pedestrian detection system based on structure and appearance classification. We discuss several novel ideas that contribute to having low-false alarms and high detection rates, while at the same time achieving computational efficiency: (i) At the front end of our system we employ stereo to detect pedestrians in 3D range maps using template matching with a representative 3D shape model, and to classify other background objects in the scene such as buildings, trees and poles. The structure classification efficiently labels substantial amount of non-relevant image regions and guides the further computationally expensive process to focus on relatively small image parts; (ii)We improve the appearance-based classifiers based on {HoG} descriptors by performing template matching with 2D human shape contour fragments that results in improved localization and accuracy; (iii) We build a suite of classifiers tuned to specific distance ranges for optimized system performance. Our method is evaluated on publicly available datasets and is shown to match or exceed the performance of leading pedestrian detectors in terms of accuracy as well as achieving real-time computation (10 Hz), which makes it adequate for in-vehicle navigation platform.},
	pages = {903--909},
	booktitle = {Proceedings - {IEEE} International Conference on Robotics and Automation},
	author = {Bansal, Mayank and Jung, Sang Hack and Matei, Bogdan and Eledath, Jayan and Sawhney, Harpreet},
	date = {2010}
}

@book{contributors_distortion_2018,
	title = {Distortion (optics)},
	url = {https://en.wikipedia.org/wiki/Distortion_(optics)},
	author = {contributors, Wikipedia},
	urldate = {2018-05-06},
	date = {2018}
}

@book{deibel_executive_2008,
	title = {Executive Summary: The Python Software Foundation},
	url = {https://www.python.org/psf/summary/},
	abstract = {the python programming language does not have a built in switch/case control structure as found in many other high level programming languages. it is thought by some that this is a deficiency in the language, and the control structure should be added. this paper demonstrates that not only is the control structure not needed, but that the methods available in python are more expressive than built in case statements in other high level languages.},
	author = {Deibel, Stephan},
	urldate = {2018-01-01},
	date = {2008}
}

@article{fleetwood_public_2017,
	title = {Public health, ethics, and autonomous vehicles},
	volume = {107},
	issn = {15410048},
	doi = {10.2105/AJPH.2016.303628},
	abstract = {With the potential to save nearly 30 000 lives per year in the United States, autonomous vehicles portend the most significant advance in auto safety history by shifting the focus from minimization of postcrash injury to collision prevention. I have delineated the important public health implications of autonomous vehicles and provided a brief analysis of a critically important ethical issue inherent in autonomous vehicle design. The broad expertise, ethical principles, and values of public health should be brought to bear on a wide range of issues pertaining to autonomous vehicles.},
	pages = {532--537},
	number = {4},
	journaltitle = {American Journal of Public Health},
	author = {Fleetwood, Janet},
	date = {2017},
	pmid = {28207327}
}

@video{nat_36_2017,
	title = {(36) How Computer Vision Is Finally Taking Off, After 50 Years - {YouTube}},
	url = {https://www.youtube.com/watch?v=eQLcDmfmGB0},
	abstract = {Computer vision is fascinating to me because a) it sounds intriguing and b) it’s a part of so many different things we use today (augmented reality, image search, Google Photos, cameras, those yellow first down lines we see watching football on {TV}, self-driving cars, selfie lenses, and more.) In this video, I talk with several researchers at Google to get an overview of the field today, a bit of its history, and a hint of its future.},
	author = {{Nat} and {Friends}},
	urldate = {2018-05-05},
	date = {2017-05-03},
	note = {https://www.youtube.com/watch?v={eQLcDmfmGB}0}
}

@article{ess_mobile_2008,
	title = {A mobile vision system for robust multi-person tracking},
	issn = {1063-6919},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587581},
	doi = {10.1109/CVPR.2008.4587581},
	abstract = {We present a mobile vision system for multi-person track- ing in busy environments. Specifically, the system integrates continuous visual odometry computation with tracking-by- detection in order to track pedestrians in spite of frequent occlusions and egomotion of the camera rig. To achieve re- liable performance under real-world conditions, it has long been advocated to extract and combine as much visual in- formation as possible. We propose a way to closely inte- grate the vision modules for visual odometry, pedestrian de- tection, depth estimation, and tracking. The integration nat- urally leads to several cognitive feedback loops between the modules. Among others, we propose a novel feedback con- nection from the object detector to visual odometry which utilizes the semantic knowledge of detection to stabilize lo- calization. Feedback loops always carry the danger that er- roneous feedback from one module is amplified and causes the entire system to become instable. We therefore incor- porate automatic failure detection and recovery, allowing the system to continue when a module becomes unreliable. The approach is experimentally evaluated on several long and difficult video sequences from busy inner-city locations. Our results show that the proposed integration makes it pos- sible to deliver stable tracking performance in scenes of previously infeasible complexity.},
	pages = {1--8},
	journaltitle = {Computer Vision and Pattern Recognition, 2008. {CVPR} 2008. {IEEE} Conference on},
	author = {Ess, a. and Leibe, B. and Schindler, K. and Van Gool, L.},
	date = {2008}
}

@book{telles_python_2008,
	title = {Python Power!: The Comprehensive Guide},
	isbn = {978-1-59863-158-6},
	url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:No+Title#0%5Cnhttp://books.google.com/books?hl=en&lr=&id=wbELAAAAQBAJ&oi=fnd&pg=PP8&dq=Python+Power!:+The+Comprehensive+Guide&ots=wz00ZeQ4IW&sig=GeXLzgvwDbvnjLDUcMxZrd3apaY},
	abstract = {A guide to the Python computer language covers such topics as data types, control flow, functions and modules, exception handling, the {GUI} library, and input and output functionality.},
	author = {Telles, M},
	date = {2008},
	keywords = {{ISBN}-13: 9781598631586}
}

@book{mallick_histogram_2016,
	title = {Histogram of Oriented Gradients in {OpenCV}},
	url = {https://www.learnopencv.com/histogram-of-oriented-gradients/},
	abstract = {In this post, we will learn the details of the Histogram of Oriented Gradients ({HOG}) feature descriptor. We will learn what is under the hood and how this descriptor is calculated internally by {OpenCV}, {MATLAB} and other packages},
	author = {Mallick, Satya},
	urldate = {2018-09-04},
	date = {2016},
	keywords = {feature descriptor, Histogram of Oriented Gradients, {HOG}, Object Detection}
}

@article{garnett_image_2007,
	title = {Image decompositions using bounded variation and generalized homogeneous Besov spaces},
	volume = {23},
	issn = {10635203},
	doi = {10.1016/j.acha.2007.01.005},
	abstract = {This paper is devoted to the decomposition of an image f into u + v, with u a piecewise-smooth or "cartoon" component, and v an oscillatory component (texture or noise), in a variational approach. Y. Meyer [Y. Meyer, Oscillating Patterns in Image Processing and Nonlinear Evolution Equations, University Lecture Series, vol. 22, Amer. Math. Soc., Providence, {RI}, 2001] proposed refinements of the total variation model [L. Rudin, S. Osher, E. Fatemi, Nonlinear total variation based noise removal algorithms, Phys. D 60 (1992) 259-268] that better represent the oscillatory part v: the weaker spaces of generalized functions G = div (L∞), F = div ({BMO}), and E = over(B, ̇)∞, ∞-1 have been proposed to model v, instead of the standard L2 space, while keeping u ∈ {BV}, a function of bounded variation. Such new models separate better geometric structures from oscillatory structures, but it is difficult to realize them in practice. D. Mumford and B. Gidas [D. Mumford, B. Gidas, Stochastic models for generic images, Quart. Appl. Math. 59 (1) (2001) 85-111] also show that natural images can be seen as samples of scale invariant probability distributions that are supported on distributions only, and not on sets of functions. In this paper, we consider and generalize Meyer's ({BV}, E) model, using the homogeneous Besov spaces over(B, ̇)p, qα, - 2 {\textbackslash}textless α {\textbackslash}textless 0, 1 ≤ p, q ≤ ∞, to represent the oscillatory part v. Theoretical, experimental results and comparisons to validate the proposed methods are presented. © 2007.},
	pages = {25--56},
	number = {1},
	journaltitle = {Applied and Computational Harmonic Analysis},
	author = {Garnett, John B. and Le, Triet M. and Meyer, Yves and Vese, Luminita A.},
	date = {2007}
}

@book{william_a._hoff_introduction_2015,
	location = {Colorado},
	title = {Introduction to Wavelets in Image Processing},
	url = {http://inside.mines.edu/ whoff/courses/EENG510/lectures/24-Wavelets.pdf},
	pagetotal = {32},
	publisher = {Colorado School of Mines, Department of Electrical Engineering and Computer Science},
	author = {{William A. Hoff}},
	date = {2015},
	keywords = {Object Detection, Wavelets}
}

@article{dixit_autonomous_2016,
	title = {Autonomous vehicles: Disengagements, accidents and reaction times},
	volume = {11},
	issn = {19326203},
	doi = {10.1371/journal.pone.0168054},
	abstract = {Autonomous vehicles are being viewed with scepticism in their ability to improve safety and the driving experience. A critical issue with automated driving at this stage of its develop- ment is that it is not yet reliable and safe. When automated driving fails, or is limited, the autonomous mode disengages and the drivers are expected to resume manual driving. For this transition to occur safely, it is imperative that drivers react in an appropriate and timely manner. Recent data released from the California trials provide compelling insights into the current factors influencing disengagements of autonomous mode. Here we show that the number of accidents observed has a significantly high correlation with the autonomous miles travelled. The reaction times to take control of the vehicle in the event of a disengage- ment was found to have a stable distribution across different companies at 0.83 seconds on average. However, there were differences observed in reaction times based on the type of disengagements, type of roadway and autonomous miles travelled. Lack of trust caused by the exposure to automated disengagements was found to increase the likelihood to take control of the vehicle manually. Further, with increased vehicle miles travelled the reaction times were found to increase, which suggests an increased level of trust with more vehicle miles travelled.Webelieve that this research would provide insurers, planners, traffic man- agement officials and engineers fundamental insights into trust and reaction times that would help them design and engineer their systems.},
	number = {12},
	journaltitle = {{PLoS} {ONE}},
	author = {Dixit, Vinayak V. and Chand, Sai and Nair, Divya J.},
	date = {2016}
}

@book{j._robert_oppenheimer_address_1945,
	location = {Los Alamos},
	title = {Address to the Association of Los Alamos Scientists},
	url = {http://www.atomicarchive.com/Docs/ManhattanProject/OppyFarewell.shtml},
	author = {{J. Robert Oppenheimer}},
	date = {1945-11},
	keywords = {Atomic Bomb}
}

@book{edmond_awad_sohan_dsouza_iyad_rahwan_azim_shariff_moral_2016,
	title = {Moral Machines},
	url = {http://moralmachine.mit.edu/},
	abstract = {The Moral Machine is a platform for gathering a human perspective on moral decisions made by machine intelligence, such as self-driving cars. We generate moral dilemmas, where a driverless car must choose the lesser of two evils, such as killing two passengers or five pedestrians. As an outside observer, people judge which outcome they think is more acceptable. They can then see how their responses compare with other people. If they are feeling creative, people can also design their own scenarios, for others to view, share, and discuss.},
	author = {Edmond Awad, Sohan Dsouza, Iyad Rahwan, Azim Shariff, Jean-François Bonnefon},
	date = {2016}
}

@article{viola_robust_2001,
	title = {Robust real-time object detection},
	volume = {57},
	issn = {09205691},
	url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Robust+Real-time+Object+Detection#0},
	doi = {http://dx.doi.org/10.1023/B:VISI.0000013087.49260.fb},
	abstract = {This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the “Integral Image” which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on {AdaBoost}, which selects a small number of critical visual features and yields extremely efficient classifiers [6]. The third contribution is a method for combining classifiers in a “cascade” which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performace comparable to the best previous systems [18, 13, 16, 12, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second.},
	pages = {137--154},
	number = {2},
	journaltitle = {International Journal of Computer Vision},
	author = {Viola, Paul and Jones, Michael},
	date = {2001},
	pmid = {7143246}
}

@book{drakos_python_2006,
	title = {Python Library Reference},
	url = {https://web.archive.org/web/20070329061639/http://www.python.org/doc/2.5/lib/node951.html},
	author = {Drakos, Nikos and Moore, Ross},
	urldate = {2018-01-01},
	date = {2006}
}

@book{cweiske_gradient2_2006,
	title = {Gradient2},
	url = {https://en.wikipedia.org/w/index.php?title=File:Gradient2.svg},
	abstract = {2 types of mathematical gradients: circular and linear one, both with arrows. The blue arrows direct from white to black.},
	publisher = {Wikipedia},
	author = {{Cweiske}},
	date = {2006}
}

@book{scott_programming_2016,
	location = {Waltham},
	edition = {4th},
	title = {Programming Language Pragmatics},
	isbn = {978-0-12-410409-9},
	abstract = {Programming Language Pragmatics, Fourth Edition, is the most comprehensive programming language textbook available today. It is distinguished and acclaimed for its integrated treatment of language design and implementation, with an emphasis on the fundamental tradeoffs that continue to drive software development. The book provides readers with a solid foundation in the syntax, semantics, and pragmatics of the full range of programming languages, from traditional languages like C to the latest in functional, scripting, and object-oriented programming. This fourth edition has been heavily revised throughout, with expanded coverage of type systems and functional programming, a unified treatment of polymorphism, highlights of the newest language standards, and examples featuring the {ARM} and x86 64-bit architectures.},
	pagetotal = {992},
	publisher = {Morgan Kaufmann},
	author = {Scott, Michael L.},
	date = {2016}
}

@book{venners_making_2003,
	title = {The Making of Python},
	url = {https://www.artima.com/intv/pythonP.html},
	abstract = {Python creator Guido van Rossum talks with Bill Venners about Python's history, the influence of the {ABC} language, and Python's original design goals.},
	author = {Venners, Bill},
	date = {2003}
}

@article{singh_critical_2015,
	title = {Critical reasons for crashes investigated in the National Motor Vehicle Crash Causation Survey},
	abstract = {The National Motor Vehicle Crash Causation Survey ({NMVCCS}), conducted from 2005 to 2007, was aimed at collecting on-scene information about the events and associated factors leading up to crashes involving light vehicles. Several facets of crash occur-rence were investigated during data collection, namely the pre-crash movement, critical pre-crash event, critical reason, and the associated factors. A weighted sample of 5,470 crashes was inves-tigated over a period of two and a half years, which represents an estimated 2,189,000 crashes nationwide. About 4,031,000 vehicles, 3,945,000 drivers, and 1,982,000 passengers were estimated to have been involved in these crashes. The critical reason, which is the last event in the crash causal chain, was assigned to the driver in 94 percent (±2.2\%) of the crashes. In about 2 percent (±0.7\%) of the crashes, the critical reason was assigned to a vehicle component's failure or degradation, and in 2 percent (±1.3\%) of crashes, it was attributed to the environment (slick roads, weather, etc.). Among an estimated 2,046,000 drivers who were assigned critical reasons, recognition errors accounted for about 41 percent (±2.1\%), deci-sion errors 33 percent (±3.7\%), and performance errors 11 percent (±2.7\%) of the crashes.},
	pages = {1--2},
	issue = {February},
	journaltitle = {National Highway Traffic Safety Administration},
	author = {Singh, Santokh},
	date = {2015},
	pmid = {1557283}
}

@article{malik_three_2016,
	title = {The three R's of computer vision: Recognition, reconstruction and reorganization},
	volume = {72},
	issn = {01678655},
	doi = {10.1016/j.patrec.2016.01.019},
	abstract = {We argue for the importance of the interaction between recognition, reconstruction and re-organization, and propose that as a unifying framework for computer vision. In this view, recognition of objects is reciprocally linked to re-organization, with bottom-up grouping processes generating candidates, which can be classified using top down knowledge, following which the segmentations can be refined again. Recognition of 3D objects could benefit from a reconstruction of 3D structure, and 3D reconstruction can benefit from object category-specific priors. We also show that reconstruction of 3D structure from video data goes hand in hand with the reorganization of the scene. We demonstrate pipelined versions of two systems, one for {RGB}-D images, and another for {RGB} images, which produce rich 3D scene interpretations in this framework.},
	pages = {4--14},
	journaltitle = {Pattern Recognition Letters},
	author = {Malik, Jitendra and Arbeláez, Pablo and Carreira, João and Fragkiadaki, Katerina and Girshick, Ross and Gkioxari, Georgia and Gupta, Saurabh and Hariharan, Bharath and Kar, Abhishek and Tulsiani, Shubham},
	date = {2016},
	pmid = {25246403},
	keywords = {Object recognition, 3D models, Action recognition: grouping, Segmentation, Shape reconstruction}
}

@incollection{amit_object_2014,
	location = {Boston, {MA}},
	title = {Object Detection},
	url = {http://link.springer.com/10.1007/978-0-387-31439-6_660},
	pages = {537--542},
	booktitle = {Computer Vision},
	publisher = {Springer {US}},
	author = {Amit, Yali and Felzenszwalb, Pedro},
	date = {2014},
	doi = {10.1007/978-0-387-31439-6_660}
}

@article{pizer_adaptive_1987,
	title = {Adaptive Histogram Equalization and its Variations},
	volume = {39},
	issn = {0734189X},
	doi = {10.1016/S0734-189X(87)80186-X},
	abstract = {Adaptive histogram equalization (ahe) is a contrast enhancement method designed to be broadly applicable and having demonstrated effectiveness. However, slow speed and the overenhancement of noise it produces in relatively homogeneous regions are two problems. We report algorithms designed to overcome these and other concerns. These algorithms include interpolated ahe, to speed up the method on general purpose computers; a version of interpolated ahe designed to run in a few seconds on feedback processors; a version of full ahe designed to run in under one second on custom {VLSI} hardware; weighted ahe, designed to improve the quality of the result by emphasizing pixels' contribution to the histogram in relation to their nearness to the result pixel; and clipped ahe, designed to overcome the problem of overenhancement of noise contrast. We conclude that clipped ahe should become a method of choice in medical imaging and probably also in other areas of digital imaging, and that clipped ahe can be made adequately fast to be routinely applied in the normal display sequence.},
	pages = {355--368},
	number = {3},
	journaltitle = {Computer vision, graphics, and image processing},
	author = {Pizer, Stephen M. and Amburn, E. Philip and Austin, John D. and Cromartie, Robert and Geselowitz, Ari and Greer, Trey and ter Haar Romeny, Bart and Zimmerman, John B. and Zuiderveld, Karel},
	date = {1987}
}

@article{an_novel_2016,
	title = {Novel intersection type recognition for autonomous vehicles using a multi-layer laser scanner},
	volume = {16},
	issn = {14248220},
	doi = {10.3390/s16071123},
	abstract = {There are several types of intersections such as merge-roads, diverge-roads, plus-shape intersections and two types of T-shape junctions in urban roads. When an autonomous vehicle encounters new intersections, it is crucial to recognize the types of intersections for safe navigation. In this paper, a novel intersection type recognition method is proposed for an autonomous vehicle using a multi-layer laser scanner. The proposed method consists of two steps: (1) static local coordinate occupancy grid map ({SLOGM}) building and (2) intersection classification. In the first step, the {SLOGM} is built relative to the local coordinate using the dynamic binary Bayes filter. In the second step, the {SLOGM} is used as an attribute for the classification. The proposed method is applied to a real-world environment and its validity is demonstrated through experimentation.},
	number = {7},
	journaltitle = {Sensors (Switzerland)},
	author = {An, Jhonghyun and Choi, Baehoon and Sim, Kwee Bo and Kim, Euntai},
	date = {2016},
	keywords = {Intersections, Local coordinate, Multi-laser scanner, Occupancy grid map, Recognition, Static map}
}

@book{van_rossum_brief_2009,
	title = {A Brief Timeline of Python},
	url = {http://python-history.blogspot.com/2009/01/brief-timeline-of-python.html},
	abstract = {The development of Python occurred at a time when many other dynamic (and open-source) programming languages such as Tcl, Perl, and (much later) Ruby were also being actively developed and gaining popularity. To help put Python in its proper historical perspective, the following list shows the release history of Python.},
	author = {van Rossum, Guido},
	date = {2009}
}

@book{rosebrock_image_2015,
	title = {Image Pyramids with Python and {OpenCV}},
	url = {https://www.pyimagesearch.com/2015/03/16/image-pyramids-with-python-and-opencv/},
	abstract = {We are going to review two ways to create image pyramids using Python, {OpenCV}, and sickit-image},
	author = {Rosebrock, Adrian},
	urldate = {2018-09-04},
	date = {2015},
	keywords = {image pyramids, object detection, classification, histogram of oriented gradients, hog, machine learning}
}

@book{schweber_shadow_2007,
	location = {New Jersey},
	edition = {E-book},
	title = {In the Shadow of the Bomb : Oppenheimer, Bethe, and the Moral Responsibility of the Scientist},
	isbn = {978-1-4008-4949-9},
	abstract = {In the Shadow of the Bomb narrates how two charismatic, exceptionally talented physicists–J. Robert Oppenheimer and Hans A. Bethe–came to terms with the nuclear weapons they helped to create. In 1945, the United States dropped the bomb, and physicists were forced to contemplate disquieting questions about their roles and responsibilities. When the Cold War followed, they were confronted with political demands for their loyalty and {McCarthyism}'s threats to academic freedom. By examining how Oppenheimer and Bethe–two men with similar backgrounds but divergent aspirations and characters–struggled with these moral dilemmas, one of our foremost historians of physics tells the story of modern physics, the development of atomic weapons, and the Cold War. Oppenheimer and Bethe led parallel lives. Both received liberal educations that emphasized moral as well as intellectual growth. Both were outstanding theoreticians who worked on the atom bomb at Los Alamos. Both advised the government on nuclear issues, and both resisted the development of the hydrogen bomb. Both were, in their youth, sympathetic to liberal causes, and both were later called to defend the United States against Soviet communism and colleagues against anti-Communist crusaders. Finally, both prized scientific community as a salve to the apparent failure of Enlightenment values. Yet, their responses to the use of the atom bomb, the testing of the hydrogen bomb, and the treachery of domestic politics differed markedly. Bethe, who drew confidence from scientific achievement and integration into the physics community, preserved a deep integrity. By accepting a modest role, he continued to influence policy and contributed to the nuclear test ban treaty of 1963. In contrast, Oppenheimer first embodied a new scientific persona–the scientist who creates knowledge and technology affecting all humanity and boldly addresses their impact–and then could not carry its burden. His desire to retain insider status, combined with his isolation from creative work and collegial scientific community, led him to compromise principles and, ironically, to lose prestige and fall victim to other insiders. Schweber draws on his vast knowledge of science and its history–in addition to his unique access to the personalities involved–to tell a tale of two men that will enthrall readers interested in science, history, and the lives and minds of great thinkers.},
	pagetotal = {288},
	publisher = {Princeton University Press},
	author = {Schweber, S. S.},
	date = {2007},
	keywords = {Atomic bomn, Biography, Moral and ethical aspects, Nuclear physicists, United States}
}

@inproceedings{viola_rapid_2001,
	title = {Rapid object detection using a boosted cascade of simple features},
	volume = {1},
	isbn = {978-0-7695-1272-3},
	url = {http://ieeexplore.ieee.org/document/990517/},
	doi = {10.1109/CVPR.2001.990517},
	pages = {I--511--I--518},
	publisher = {{IEEE} Comput. Soc},
	author = {Viola, P. and Jones, M.},
	urldate = {2018-05-07},
	date = {2001},
	file = {Viola and Jones - 2001 - Rapid object detection using a boosted cascade of .pdf:C\:\\Users\\bass1\\Zotero\\storage\\EBTB8WHS\\Viola and Jones - 2001 - Rapid object detection using a boosted cascade of .pdf:application/pdf}
}

@article{zemek_effect_1975,
	title = {Effect of some aldoses on growth of Saccharomyces cerevisiae inhibited with molybdenum},
	volume = {20},
	issn = {0015-5632},
	abstract = {The inhibitory effect of molybdenum ions on growth of yeasts at {pH} 5.5 was found to be decreased by aldoses in the following order: D-talose greater than L-mannose greater than L-ribose greater than D-lyxose greater than L-galactose greater than L-arabinose greater than L-glucose greater than L-xylose. Increased concentrations of molybdenum brought about morphological changes of yeast cells. Cells grown under these conditions were smaller, had thicker walls and formed clusters.},
	pages = {467--469},
	number = {6},
	journaltitle = {Folia Microbiologica},
	shortjournal = {Folia Microbiol. (Praha)},
	author = {Zemek, J. and Bílik, V. and Zákutná, L.},
	date = {1975},
	pmid = {285},
	keywords = {Arabinose, Carbohydrates, Cell Wall, Galactose, Glucose, Hydrogen-Ion Concentration, Mannose, Molybdenum, Ribose, Saccharomyces cerevisiae, Stereoisomerism, Xylose}
}

@book{larson_calculus_2014,
	location = {Boston, {MA}},
	edition = {10e},
	title = {Calculus},
	isbn = {978-1-285-05709-5},
	pagetotal = {1124},
	publisher = {Brooks/Cole, Cengage Learning},
	author = {Larson, Ron and Edwards, Bruce H.},
	date = {2014},
	keywords = {Calculus, Textbooks}
}

@article{baripada_college_hungarian_2017,
	title = {Hungarian Method to Solve Travelling Salesman Problem with Fuzzy Cost},
	volume = {49},
	issn = {22315373},
	url = {http://www.ijmttjournal.org/archive/ijmtt-v49p544},
	doi = {10.14445/22315373/IJMTT-V49P544},
	pages = {281--284},
	number = {5},
	journaltitle = {International Journal of Mathematics Trends and Technology},
	author = {{Baripada College} and Nayak, Jadunath and Nanda, Sudarsan},
	urldate = {2018-05-07},
	date = {2017-09-25}
}

@book{kolman_elementary_2008,
	location = {Upper Saddle River, N.J},
	edition = {9th ed},
	title = {Elementary linear algebra with applications},
	isbn = {978-0-13-229654-0 978-0-13-135063-2},
	pagetotal = {1},
	publisher = {Pearson Prentice Hall},
	author = {Kolman, Bernard and Hill, David R.},
	date = {2008},
	note = {{OCLC}: ocn148033544},
	keywords = {Algebras, Linear}
}

@online{simon_perkins;_ashley_walker;_erik_wolfart_spatial_2000,
	title = {Spatial Filters - Gaussian Smoothing},
	url = {http://homepages.inf.ed.ac.uk/rbf/HIPR2/gsmooth.htm},
	titleaddon = {Hypermedia Image Processing Reference},
	author = {{Simon Perkins; Ashley Walker; Erik Wolfart}},
	urldate = {2018-05-08},
	date = {2000},
	file = {Spatial Filters - Gaussian Smoothing:C\:\\Users\\bass1\\Zotero\\storage\\6LIMW4NJ\\gsmooth.html:text/html}
}

@online{_histogram_????,
	title = {Histogram equalization - The Full Wiki},
	url = {http://www.thefullwiki.org/Histogram_equalization},
	urldate = {2018-05-08},
	file = {Histogram equalization - The Full Wiki:C\:\\Users\\bass1\\Zotero\\storage\\3FGXQCQ8\\Histogram_equalization.html:text/html}
}

@online{_elimination_2011,
	title = {The elimination method for solving linear systems (Algebra 1, Systems of linear equations and inequalities)},
	url = {https://www.mathplanet.com/education/algebra-1/systems-of-linear-equations-and-inequalities/the-elimination-method-for-solving-linear-systems},
	titleaddon = {Mathplanet},
	urldate = {2018-05-11},
	date = {2011},
	langid = {english},
	file = {Snapshot:C\:\\Users\\bass1\\Zotero\\storage\\DM73YAT8\\the-elimination-method-for-solving-linear-systems.html:text/html}
}

@online{weisstein_echelon_2018,
	title = {Echelon Form},
	rights = {Copyright 1999-2018 Wolfram Research, Inc.  See http://mathworld.wolfram.com/about/terms.html for a full terms of use statement.},
	url = {http://mathworld.wolfram.com/EchelonForm.html},
	abstract = {A matrix that has undergone Gaussian elimination is said to be in row echelon form or, more properly, "reduced echelon form" or "row-reduced echelon form." Such a matrix has the following characteristics: 1. All zero rows are at the bottom of the matrix  2. The leading entry of each nonzero row after the first occurs to the right of the leading entry of the previous row.  3. The leading entry in any nonzero row is 1.  4. All entries in the column above and below a leading...},
	type = {Text},
	author = {Weisstein, Eric W.},
	urldate = {2018-05-11},
	date = {2018},
	langid = {english},
	file = {Snapshot:C\:\\Users\\bass1\\Zotero\\storage\\4V9XXMJG\\EchelonForm.html:text/html}
}

@online{weisstein_vector_2018,
	title = {Vector Space},
	rights = {Copyright 1999-2018 Wolfram Research, Inc.  See http://mathworld.wolfram.com/about/terms.html for a full terms of use statement.},
	url = {http://mathworld.wolfram.com/VectorSpace.html},
	abstract = {A vector space V is a set that is closed under finite vector addition and scalar multiplication. The basic example is n-dimensional Euclidean space R{\textasciicircum}n, where every element is represented by a list of n real numbers, scalars are real numbers, addition is componentwise, and scalar multiplication is multiplication on each term separately. For a general vector space, the scalars are members of a field F, in which case V is called a vector space over F. Euclidean n-space R{\textasciicircum}n is called a real...},
	type = {Text},
	author = {Weisstein, Eric W.},
	urldate = {2018-05-11},
	date = {2018},
	langid = {english},
	file = {Snapshot:C\:\\Users\\bass1\\Zotero\\storage\\2WA3BXS2\\VectorSpace.html:text/html}
}